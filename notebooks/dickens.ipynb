{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nrhodes/.local/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n",
      "/home/nrhodes/.local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import fastai\n",
    "\n",
    "from fastai.io import *\n",
    "\n",
    "from fastai.column_data import *\n",
    "from fastai.text import *\n",
    "\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to generate Dickens-like text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davidcopperfield.txt  \u001b[0m\u001b[01;34mmodels\u001b[0m/  \u001b[01;34mtmp\u001b[0m/  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "PATH=Path('../data/dickens/')\n",
    "\n",
    "TRN_PATH = 'trn'\n",
    "VAL_PATH = 'val'\n",
    "TRN = PATH / TRN_PATH\n",
    "VAL = PATH / VAL_PATH\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 53, 1, 1494913)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=2048; bptt=16; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSequence(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.dropout = nn.Dropout(.1)\n",
    "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.0)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.dropout(self.e(cs)), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d68372f38b544a7a8f62b380000bc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=127), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      2.572774   2.276912  \n",
      "    1      2.115803   1.784056  \n",
      "    2      1.863651   1.711806  \n",
      "    3      1.722404   1.592232  \n",
      "    4      1.609507   1.538926  \n",
      "    5      1.540361   1.505572  \n",
      "    6      1.493371   1.499538  \n",
      "    7      1.488782   1.507937  \n",
      "    8      1.46603    1.473991  \n",
      "    9      1.437556   1.456916  \n",
      "    10     1.412901   1.440341  \n",
      "    11     1.391879   1.428559  \n",
      "    12     1.373634   1.414256  \n",
      "    13     1.361996   1.406121  \n",
      "    14     1.350272   1.409307  \n",
      "    15     1.380842   1.452749  \n",
      "    16     1.383146   1.434688  \n",
      "    17     1.376513   1.428363  \n",
      "    18     1.368166   1.425418  \n",
      "    19     1.358563   1.404775  \n",
      "    20     1.348451   1.404826  \n",
      "    21     1.338716   1.393615  \n",
      "    22     1.328626   1.386471  \n",
      "    23     1.320264   1.388079  \n",
      "    24     1.311041   1.379866  \n",
      "    25     1.303094   1.374781  \n",
      "    26     1.294717   1.368882  \n",
      "    27     1.285488   1.362586  \n",
      "    28     1.278437   1.361251  \n",
      "    29     1.27424    1.362368  \n",
      "    30     1.272064   1.362655  \n",
      "    31     1.320805   1.407533  \n",
      "    32     1.327176   1.390317  \n",
      "    33     1.327967   1.399115  \n",
      "    34     1.326519   1.396821  \n",
      "    35     1.327837   1.401842  \n",
      "    36     1.326898   1.388387  \n",
      "    37     1.319625   1.38949   \n",
      "    38     1.31428    1.390682  \n",
      "    39     1.307686   1.380698  \n",
      "    40     1.301179   1.379527  \n",
      "    41     1.294102   1.385189  \n",
      "    42     1.290543   1.378699  \n",
      "    43     1.28935    1.382157  \n",
      "    44     1.285216   1.378189  \n",
      "    45     1.281049   1.370306  \n",
      "    46     1.271913   1.367498  \n",
      "    47     1.269603   1.362169  \n",
      "    48     1.263732   1.367457  \n",
      "    49     1.261101   1.356912  \n",
      "    50     1.267013   1.358748  \n",
      "    51     1.255581   1.362308  \n",
      "    52     1.247944   1.345965  \n",
      "    53     1.243045   1.343802  \n",
      "    54     1.236225   1.345955  \n",
      "    55     1.23757    1.335267  \n",
      "    56     1.237017   1.342581  \n",
      "    57     1.229145   1.338221  \n",
      "    58     1.226848   1.332684  \n",
      "    59     1.222769   1.334529  \n",
      "    60     1.220845   1.337044  \n",
      "    61     1.224618   1.33495   \n",
      "    62     1.222261   1.337484  \n",
      "    63     1.267332   1.396591  \n",
      "    64     1.287724   1.378634  \n",
      "    65     1.295214   1.381238  \n",
      "    66     1.293262   1.382992  \n",
      "    67     1.29188    1.397386  \n",
      "    68     1.287802   1.368003  \n",
      "    69     1.283528   1.376609  \n",
      "    70     1.287659   1.37187   \n",
      "    71     1.282976   1.37134   \n",
      "    72     1.285144   1.370959  \n",
      "    73     1.279776   1.364701  \n",
      "    74     1.282098   1.372546  \n",
      "    75     1.275244   1.366792  \n",
      "    76     1.270443   1.373073  \n",
      "    77     1.268208   1.377179  \n",
      "    78     1.26528    1.373977  \n",
      "    79     1.275098   1.368572  \n",
      "    80     1.266492   1.36217   \n",
      "    81     1.26092    1.355284  \n",
      "    82     1.257561   1.350556  \n",
      "    83     1.256755   1.364231  \n",
      "    84     1.257456   1.353756  \n",
      "    85     1.252185   1.372322  \n",
      "    86     1.259181   1.368972  \n",
      "    87     1.254647   1.363724  \n",
      "    88     1.250987   1.350148  \n",
      "    89     1.245433   1.354858  \n",
      "    90     1.245846   1.350206  \n",
      "    91     1.239744   1.350101  \n",
      "    92     1.239475   1.366242  \n",
      "    93     1.237953   1.35929   \n",
      "    94     1.238396   1.347816  \n",
      "    95     1.23424    1.342477  \n",
      "    96     1.228844   1.345559  \n",
      "    97     1.225197   1.349571  \n",
      "    98     1.221526   1.341464  \n",
      "    99     1.222258   1.345122  \n",
      "   100     1.220635   1.342516  \n",
      "   101     1.219434   1.340988  \n",
      "   102     1.218856   1.339743  \n",
      "   103     1.218712   1.336335  \n",
      "   104     1.224348   1.340212  \n",
      "   105     1.221034   1.345038  \n",
      "   106     1.211637   1.334953  \n",
      "   107     1.206964   1.338004  \n",
      "   108     1.209707   1.328451  \n",
      "   109     1.209935   1.338854  \n",
      "   110     1.201912   1.325153  \n",
      "   111     1.203351   1.335982  \n",
      "   112     1.196147   1.325753  \n",
      "   113     1.194387   1.327283  \n",
      "   114     1.189138   1.321657  \n",
      "   115     1.191694   1.325721  \n",
      "   116     1.191617   1.324465  \n",
      "   117     1.186923   1.319702  \n",
      "   118     1.191476   1.321562  \n",
      "   119     1.18391    1.318858  \n",
      "   120     1.181589   1.328004  \n",
      "   121     1.181373   1.320227  \n",
      "   122     1.178551   1.319881  \n",
      "   123     1.179402   1.321058  \n",
      "   124     1.180548   1.322342  \n",
      "   125     1.177955   1.31851   \n",
      "   126     1.177886   1.317816  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.31782])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = BasicModel(CharSequence(md.nt, n_fac, n_hidden, 1).cuda())\n",
    "learner = RNN_Learner(md, m, opt_fn=optim.Adam, crit=F.nll_loss)\n",
    "\n",
    "#minimum_learning_rate_divisor = 1200\n",
    "#percent_after_triangle_cycle = 15\n",
    "#max_momentum=.97\n",
    "#min_momentum=.85\n",
    "#learner.fit(1e-2, 1, cycle_len=72, \n",
    "#           use_clr_beta=(minimum_learning_rate_divisor, \n",
    "#                         percent_after_triangle_cycle, \n",
    "#                         max_momentum, \n",
    "#                         min_momentum),\n",
    "#                         wds=1e-5)\n",
    "learner.fit(2e-2, 7, cycle_mult=2, cycle_len=1, \n",
    "           wds=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = learner.model(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')\n",
    "#TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourscore and seven years ago, as a repelled youngman, comes, claraves, peggotty possessed as to the ground falls street and kind of a tea?)‘i will not help that. you must be disorder that you read, after boys to speak rounded, my mother, didn’t be taken to us you, sir,’ said my aunt. ‘they were notexprause a nighty more. my love from an agreeable life, inexpected myself, then when i am often could be happy himselfback afore \n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('fourscore and seven years ago', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs152]",
   "language": "python",
   "name": "conda-env-cs152-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "216px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
