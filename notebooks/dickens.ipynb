{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import fastai\n",
    "\n",
    "from fastai.io import *\n",
    "\n",
    "from fastai.column_data import *\n",
    "from fastai.text import *\n",
    "\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to generate Dickens-like text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davidcopperfield.txt  \u001b[0m\u001b[01;34mmodels\u001b[0m/  \u001b[01;34mtmp\u001b[0m/  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "PATH=Path('../data/dickens/')\n",
    "\n",
    "TRN_PATH = 'trn'\n",
    "VAL_PATH = 'val'\n",
    "TRN = PATH / TRN_PATH\n",
    "VAL = PATH / VAL_PATH\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 53, 1, 1494913)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=2048; bptt=16; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharSequence(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.dropout = nn.Dropout(.1)\n",
    "        self.rnn = nn.GRU(n_fac, n_hidden, nl, dropout=0.0)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.dropout(self.e(cs)), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = V(torch.zeros(self.nl, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f33241988c4824876068de69ed0fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=127), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      2.598663   2.305043  \n",
      "    1      2.208407   1.921305  \n",
      "    2      2.002703   1.863702  \n",
      "    3      1.881645   1.773078  \n",
      "    4      1.813082   1.715943  \n",
      "    5      1.750779   1.700081  \n",
      "    6      1.699288   1.673854  \n",
      "    7      1.69325    1.676341  \n",
      "    8      1.669341   1.651264  \n",
      "    9      1.6614     1.618604  \n",
      "    10     1.642774   1.623783  \n",
      "    11     1.634357   1.608566  \n",
      "    12     1.60647    1.586232  \n",
      "    13     1.58998    1.58007   \n",
      "    14     1.580077   1.583153  \n",
      "    15     1.603731   1.630319  \n",
      "    16     1.615242   1.612495  \n",
      "    17     1.617313   1.60939   \n",
      "    18     1.612678   1.606043  \n",
      "    19     1.621265   1.596941  \n",
      "    20     1.59347    1.578293  \n",
      "    21     1.597405   1.60619   \n",
      "    22     1.582763   1.573977  \n",
      "    23     1.558387   1.582913  \n",
      "    24     1.551436   1.553195  \n",
      "    25     1.538836   1.569853  \n",
      "    26     1.531411   1.510865  \n",
      "    27     1.531785   1.575031  \n",
      "    28     1.524847   1.539582  \n",
      "    29     1.510147   1.522369  \n",
      "    30     1.527282   1.556033  \n",
      "    31     1.564018   1.592315  \n",
      "    32     1.585498   1.592848  \n",
      "    33     1.584731   1.591917  \n",
      "    34     1.584881   1.599321  \n",
      "    35     1.586509   1.618033  \n",
      "    36     1.58605    1.565415  \n",
      "    37     1.59372    1.600245  \n",
      "    38     1.573813   1.602568  \n",
      "    39     1.564221   1.581921  \n",
      "    40     1.559994   1.55472   \n",
      "    41     1.557939   1.554321  \n",
      "    42     1.545737   1.555136  \n",
      "    43     1.549052   1.538389  \n",
      "    44     1.535668   1.568595  \n",
      "    45     1.528412   1.532657  \n",
      "    46     1.516309   1.548538  \n",
      "    47     1.508929   1.541163  \n",
      "    48     1.51988    1.527805  \n",
      "    49     1.510024   1.532351  \n",
      "    50     1.508722   1.520981  \n",
      "    51     1.50695    1.55396   \n",
      "    52     1.512869   1.515608  \n",
      "    53     1.51576    1.53259   \n",
      "    54     1.490482   1.477109  \n",
      "    55     1.476037   1.493984  \n",
      "    56     1.48252    1.514784  \n",
      "    57     1.478372   1.511131  \n",
      "    58     1.47758    1.48325   \n",
      "    59     1.477373   1.499712  \n",
      "    60     1.48567    1.498663  \n",
      "    61     1.468115   1.50117   \n",
      "    62     1.465444   1.503719  \n",
      "    63     1.541124   1.569389  \n",
      "    64     1.559516   1.575184  \n",
      "    65     1.54986    1.570725  \n",
      "    66     1.553148   1.580586  \n",
      "    67     1.545949   1.569276  \n",
      "    68     1.57171    1.604841  \n",
      "    69     1.569688   1.583466  \n",
      "    70     1.553184   1.543236  \n",
      "    71     1.536719   1.549043  \n",
      "    72     1.544878   1.576205  \n",
      "    73     1.554319   1.586287  \n",
      "    74     1.563318   1.570742  \n",
      "    75     1.568934   1.56514   \n",
      "    76     1.564512   1.583051  \n",
      "    77     1.537452   1.558109  \n",
      "    78     1.540293   1.55378   \n",
      "    79     1.528745   1.541123  \n",
      "    80     1.534393   1.601585  \n",
      "    81     1.531722   1.541394  \n",
      "    82     1.526589   1.564584  \n",
      "    83     1.53672    1.543271  \n",
      "    84     1.521146   1.53717   \n",
      "    85     1.531251   1.549004  \n",
      "    86     1.514379   1.545011  \n",
      "    87     1.526782   1.565702  \n",
      "    88     1.517572   1.541539  \n",
      "    89     1.537539   1.541409  \n",
      "    90     1.509944   1.551645  \n",
      "    91     1.504762   1.510963  \n",
      "    92     1.502554   1.505922  \n",
      "    93     1.503583   1.531567  \n",
      "    94     1.487517   1.523211  \n",
      "    95     1.501519   1.515817  \n",
      "    96     1.509622   1.522994  \n",
      "    97     1.484858   1.508426  \n",
      "    98     1.503299   1.509934  \n",
      "    99     1.483196   1.537162  \n",
      "   100     1.485229   1.539581  \n",
      "   101     1.480252   1.532464  \n",
      "   102     1.466938   1.482793  \n",
      "   103     1.47099    1.492027  \n",
      "   104     1.479575   1.516102  \n",
      "   105     1.474742   1.511056  \n",
      "   106     1.47103    1.479666  \n",
      "   107     1.468106   1.488606  \n",
      "   108     1.483953   1.501701  \n",
      "   109     1.484516   1.477982  \n",
      "   110     1.476446   1.508162  \n",
      "   111     1.455878   1.473067  \n",
      "   112     1.454026   1.471007  \n",
      "   113     1.462809   1.469973  \n",
      "   114     1.458824   1.486265  \n",
      "   115     1.45447    1.495293  \n",
      "   116     1.453485   1.479891  \n",
      "   117     1.451281   1.533258  \n",
      "   118     1.441293   1.467551  \n",
      "   119     1.463665   1.498735  \n",
      "   120     1.449375   1.490169  \n",
      "   121     1.454912   1.479453  \n",
      "   122     1.463447   1.473486  \n",
      "   123     1.436638   1.476497  \n",
      "   124     1.4299     1.505883  \n",
      "   125     1.419811   1.49015   \n",
      "   126     1.430423   1.502348  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.50235])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = BasicModel(CharSequence(md.nt, n_fac, n_hidden, 1).cuda())\n",
    "learner = RNN_Learner(md, m, opt_fn=optim.Adam, crit=F.nll_loss)\n",
    "\n",
    "#minimum_learning_rate_divisor = 1200\n",
    "#percent_after_triangle_cycle = 15\n",
    "#max_momentum=.97\n",
    "#min_momentum=.85\n",
    "#learner.fit(1e-2, 1, cycle_len=72, \n",
    "#           use_clr_beta=(minimum_learning_rate_divisor, \n",
    "#                         percent_after_triangle_cycle, \n",
    "#                         max_momentum, \n",
    "#                         min_momentum),\n",
    "#                         wds=1e-5)\n",
    "learner.fit(2e-2, 7, cycle_mult=2, cycle_len=1, \n",
    "           wds=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = learner.model(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')\n",
    "#TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourscore and seven years agony. the otherwise my arm for purious for a convenience.‘i only see it?’‘from the first singularly way, grivalicloney of her. i lived thoughtn’s pass on, which i faintly, the edid old looks in favour off.’‘when you as this?’ said traddles, standing into sigh?’‘i am called until your counter with the prina’ leconsent, trot, mr. micawber for the countenance neighbours ofthe ficse, i was not allusion \n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('fourscore and seven years ago', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs152]",
   "language": "python",
   "name": "conda-env-cs152-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "216px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
