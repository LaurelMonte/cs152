{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 6 notebook\n",
    "## CS152 September 23, 2018  Neil Rhodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $f(x_1, x_2, x_3, w_1, w_2, b) = \\frac{1}{1 + e^{-(w_1x_1 + w_2x_2 + b)}}$, we want to find $\\frac{\\partial{f}}{{w_1}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an evaluation graph showing the various operations.  We name each node with a single letter:\n",
    "\n",
    "![Evaluation Graph](images/evaluation_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def a(x1, w1):\n",
    "    return x1 * w1\n",
    "\n",
    "def c(x2, w2):\n",
    "    return x2 * w2\n",
    "\n",
    "def d(a, b, c):\n",
    "    return a + b + c\n",
    "\n",
    "def e(d):\n",
    "    return -d\n",
    "\n",
    "def h(e):\n",
    "    return math.exp(e)\n",
    "\n",
    "def i(h):\n",
    "    return h + 1\n",
    "\n",
    "def j(i):\n",
    "    return 1/i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Differentiation\n",
    "Here, we calculate via numeric differentation, the value $\\frac{\\partial{f}}{{w_1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f: 0.73\n",
      "df/dw1: 0.59\n"
     ]
    }
   ],
   "source": [
    "x1=3.0\n",
    "w1=1.0\n",
    "x2=-2.0\n",
    "w2=2.0\n",
    "b=2.0\n",
    "\n",
    "f = j(i(h(e(d(c(x2, w2), a(x1, w1), b)))))\n",
    "print(f'f: {f:.2f}')\n",
    "\n",
    "epsilon = .000001\n",
    "fepsilon = j(i(h(e(d(c(x2, w2), a(x1, w1+epsilon), b)))))\n",
    "df_dw1 = (fepsilon-f)/epsilon\n",
    "print(f'df/dw1: {df_dw1:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the output value of each node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 3.00\n",
      "c: -4.00\n",
      "d: 1.00\n",
      "e: -1.00\n",
      "h: 0.37\n",
      "i: 1.37\n",
      "f: 0.73\n"
     ]
    }
   ],
   "source": [
    "a_out=a(x1, w1)\n",
    "c_out=c(x2, w2)\n",
    "d_out=d(a_out, c_out, b)\n",
    "e_out=e(d_out)\n",
    "h_out=h(e_out)\n",
    "i_out=i(h_out)\n",
    "j_out=j(i_out)\n",
    "f = j_out\n",
    "print(f\"a: {a_out:0.2f}\")\n",
    "print(f\"c: {c_out:0.2f}\")\n",
    "print(f\"d: {d_out:0.2f}\")\n",
    "print(f\"e: {e_out:0.2f}\")\n",
    "print(f\"h: {h_out:0.2f}\")\n",
    "print(f\"i: {i_out:0.2f}\")\n",
    "print(f\"f: {f:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "Now, we'll do backpropagation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/di: -0.53\n",
      "df/dh: -0.53\n",
      "df/de: -0.20\n",
      "df/dd: 0.20\n",
      "df/dc: 0.20\n",
      "df/da: 0.20\n",
      "df/dw1: 0.59\n",
      "df/dw2: -0.39\n",
      "df/db: 0.20\n"
     ]
    }
   ],
   "source": [
    "def da_dw1(w1):\n",
    "    # a(x1, w1) = x1 * w1\n",
    "    return x1\n",
    "\n",
    "def dc_dw2(w2):\n",
    "    # c(x2, w2) = x2 * w2\n",
    "    return x2\n",
    "\n",
    "def dd_da(a):\n",
    "    # d(a) = a + b + c\n",
    "    return 1\n",
    "\n",
    "def dd_db(b):\n",
    "    # d(a) = a + b + c\n",
    "    return 1\n",
    "\n",
    "def dd_dc(c):\n",
    "    # d(a) = a + b + c\n",
    "    return 1\n",
    "\n",
    "def de_dd(d):\n",
    "    # e(d) = -d\n",
    "    return -1\n",
    "\n",
    "def dh_de(e):\n",
    "    # h(e) = math.exp(e)\n",
    "    return math.exp(e)\n",
    "\n",
    "def di_dh(h):\n",
    "    #i(h) = h + 1\n",
    "    return 1\n",
    "\n",
    "def dj_di(i):\n",
    "    #j(i) = 1/i\n",
    "    return -1/(i*i)\n",
    "\n",
    "def df_dj(j):\n",
    "    #f(j) = j\n",
    "    return 1\n",
    "\n",
    "df_di_out = df_dj(j_out) * dj_di(i_out)\n",
    "df_dh_out = df_di_out * di_dh(h_out)\n",
    "df_de_out = df_dh_out * dh_de(e_out)\n",
    "df_dd_out = df_de_out * de_dd(d_out)\n",
    "df_dc_out = df_dd_out * dd_dc(c_out)\n",
    "df_da_out = df_dc_out * dd_da(a_out)\n",
    "df_dw1_out = df_da_out * da_dw1(w1)\n",
    "df_dw2_out = df_dc_out * dc_dw2(w2)\n",
    "df_db_out = df_dd_out * dd_db(b)\n",
    "print(f'df/di: {df_di_out:.2f}')\n",
    "print(f'df/dh: {df_dh_out:.2f}')\n",
    "print(f'df/de: {df_de_out:.2f}')\n",
    "print(f'df/dd: {df_dd_out:.2f}')\n",
    "print(f'df/dc: {df_dc_out:.2f}')\n",
    "print(f'df/da: {df_da_out:.2f}')\n",
    "print(f'df/dw1: {df_dw1_out:.2f}')\n",
    "print(f'df/dw2: {df_dw2_out:.2f}')\n",
    "print(f'df/db: {df_db_out:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Differentiation using PyTorch\n",
    "Let's look at how to differentiate using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(...) =  Variable containing:\n",
      " 0.7311\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "df/dw1: Variable containing:\n",
      " 0.5898\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "df/dw2: Variable containing:\n",
      "-0.3932\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "df/db: Variable containing:\n",
      " 0.1966\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "\n",
    "def f(x1, x2, w1, w2, b):\n",
    "    weightedSum = x1*w1 + x2*w2 + b\n",
    "    return 1/(1+torch.exp(-weightedSum))\n",
    "\n",
    "x1 = Variable(Tensor([3.0])) # in pyTorch ≥0.4: x1 = Tensor([3.0])\n",
    "w1 = Variable(Tensor([1.0]), requires_grad=True) # in pyTorch ≥0.4: w1 = Tensor([1.0], requires_grad=True)\n",
    "x2 = Variable(Tensor([-2.0]))\n",
    "w2 = Variable(Tensor([2.0]), requires_grad=True)\n",
    "b = Variable(Tensor([2.0]), requires_grad=True)\n",
    "\n",
    "result = f(x1, x2, w1, w2, b)\n",
    "print(\"f(...) = \", result)\n",
    "\n",
    "result.backward()\n",
    "print(f'df/dw1: {w1.grad}')\n",
    "print(f'df/dw2: {w2.grad:}')\n",
    "print(f'df/db: {b.grad:}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, using matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(...) =  Variable containing:\n",
      " 0.7311\n",
      "[torch.FloatTensor of size 1x1]\n",
      "\n",
      "df/dw: Variable containing:\n",
      " 0.5898\n",
      "-0.3932\n",
      "[torch.FloatTensor of size 2x1]\n",
      "\n",
      "df/db: Variable containing:\n",
      " 0.1966\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "\n",
    "def sigmoid_layer(w, x, b):\n",
    "    return sigmoid(torch.mm(w.t(), x)+ b)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def relu_layer(w, x, b):\n",
    "    return relu(torch.mm(w.t(), x)+ b)\n",
    "\n",
    "def relu(x):\n",
    "    return x.clamp(min=0)\n",
    "\n",
    "\n",
    "x = Variable(Tensor([[3.0], [-2.0]])) # shape: (2, 1)\n",
    "w = Variable(Tensor([[1.0], [2.0]]), requires_grad=True) # shape: (2, 1)\n",
    "b = Variable(Tensor([2.0]), requires_grad=True)\n",
    "\n",
    "a1 = sigmoid_layer(x, w, b)\n",
    "print(\"f(...) = \", a1)\n",
    "\n",
    "a1.backward()\n",
    "print(f'df/dw: {w.grad}')\n",
    "print(f'df/db: {b.grad:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch4]",
   "language": "python",
   "name": "conda-env-pytorch4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
